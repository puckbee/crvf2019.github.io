<!DOCTYPE html>
<html>
<head>
	<title>Princeton Vision &amp; Robotics Group</title>
	<link rel="stylesheet" type="text/css" href="pvg.css">
</head>
<body>
<script type="text/javascript" src="header.js"></script>

<p style=" padding-top: 30px;">
<a href="https://scholar.google.com/citations?user=k1cGv3MAAAAJ&hl=en">Google Scholar</a>
&nbsp;&#183;&nbsp; 
<a href="pvg.bib">Bibtex</a>
&nbsp;&#183;&nbsp;
<a href="http://dblp.uni-trier.de/pers/hd/f/Funkhouser:Thomas_A=">DBLP</a>
</p>

<table id="pubList" border=0 cellpadding=0 width=100% style="border-spacing: 0 6px; line-height:14pt;">

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/SSCNet/thumbnail.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>S. Song, F.Yu, A. Zeng, A. Chang, M. Savva, and T. Funkhouser <br>
			<a href="https://arxiv.org/pdf/1611.08974v1.pdf"><b>Semantic Scene Completion from a Single Depth Image</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="https://arxiv.org/pdf/1611.08974v1.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://sscnet.cs.princeton.edu/">Project Webpage</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=Yjpmouaap6M"><img src="/projects/2016/SSCNet/video.jpg" style="width: 130px; height: 85px;"/></a>
			
			</td>
			</tr></table>			
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/3DMatch/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>A. Zeng, S. Song, M. Nießner, M. Fisher, J. Xiao, and T. Funkhouser<br>
			<a href="http://3DMatch.cs.princeton.edu"><b>3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="https://arxiv.org/pdf/1603.08182v2.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://3DMatch.cs.princeton.edu">Project Webpage</a>&nbsp;&#183;&nbsp;
				<a href="https://github.com/andyzeng/3dmatch-toolbox">Source Code</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=gZrsJJtDvvA"><img src="/projects/2016/3DMatch/video.jpg" style="margin-top: 6px; width: 130px; height: 75px;"/></a>

			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/misc/fyu-thumbnail1.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>H. Xu, Y. Gao, F. Yu, and T. Darrell<br>
			<a href="https://arxiv.org/pdf/1612.01079.pdf"><b>End-to-end Learning of Driving Models from Large-scale Video Datasets</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="https://arxiv.org/pdf/1612.01079.pdf">Paper</a>
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/ScanNet/thumbnail.png"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>A. Dai, A. Chang, M. Savva, M. Halber, T. Funkhouser, and M. Nießner<br>
			<a href="https://arxiv.org/pdf/1702.04405.pdf"><b>ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<b style="color: #EE7F2D;">Spotlight Presentation</b>&nbsp;&#183;&nbsp;
				<a href="https://arxiv.org/pdf/1702.04405.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://www.scan-net.org/">Project Webpage</a>&nbsp;&#183;&nbsp;
				<a href="https://github.com/ScanNet/ScanNet">Source Code</a>
			</p>
			</td><td style="width: 10px;">


			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/StructuredGlobalRegistration/teaser.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>M. Halber and T. Funkhouser<br>
			<a href="https://arxiv.org/pdf/1607.08539v3.pdf"><b>Fine-To-Coarse Global Registration of RGB-D Scans</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<a href="https://arxiv.org/pdf/1607.08539v3.pdf">Paper</a>&nbsp;&#183;&nbsp;
				Project Webpage
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="projects/2016/PBRS/icon.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>Y. Zhang*, S. Song*, E. Yumer, M. Savva, J. Lee, H. Jin, and T. Funkhouser<br>
			<a href="https://arxiv.org/pdf/1612.07429v2.pdf"><b>Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<a href="https://arxiv.org/pdf/1612.07429v2.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="projects/2016/PBRS/">Project Webpage</a>
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/dilation/dilation_thumb.png"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>F. Yu, V. Koltun, and T. Funkhouser<br>
			<b>Dilated Residual Networks</b><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				Paper
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/misc/fyu-thumbnail2.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>P. Sangkloy, J. Lu, C. Fang, F. Yu, and J. Hays<br>
			<a href="https://arxiv.org/pdf/1612.00835.pdf"><b>Scribbler: Controlling Deep Image Synthesis with Sketch and Color</b></a><br>
				IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2017</b>)<br>
				<a href="https://arxiv.org/pdf/1612.00835.pdf">Paper</a>&nbsp;&#183;&nbsp;
				Project Webpage
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/apc/robot.png"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>A. Zeng, K.T. Yu, S. Song, D. Suo, E. Walker Jr., A. Rodriguez, and J. Xiao<br>
			<a href="http://apc.cs.princeton.edu/"><b>Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the Amazon Picking Challenge</b></a><br>
				IEEE International Conference on Robotics and Automation (<b>ICRA2017</b>)<br>
				<a href="https://arxiv.org/pdf/1609.09475v2.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://apc.cs.princeton.edu/">Project Webpage and Dataset</a>&nbsp;&#183;&nbsp;
				<a href="https://github.com/andyzeng/apc-vision-toolbox">Source Code</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=BjL-DW4jVEM"><img src="/projects/2016/apc/video.jpg" style="width: 130px; height: 85px;"/></a>
			
			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="https://dl.dropboxusercontent.com/u/7775117/jianxiongxiao.com/projects/2016/MapNet/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>A. Seff and J. Xiao.<br>
			<a href="https://arxiv.org/pdf/1611.08583v1.pdf"><b>Learning from Maps: Visual Common Sense for Autonomous Driving</b></a><br>
				arxiv:1611.08583 [cs.2016] (25 Nov 2016)<br>
				<a href="https://arxiv.org/pdf/1611.08583.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href='http://www.cs.princeton.edu/~aseff/mapnet/'>Project Webpage</a>&nbsp;&#183;&nbsp;
				<a href='https://github.com/ariseff/mapnet'>Source Code</a>
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>		

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/DSS/thumbnail.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>S. Song, and J. Xiao<br>
			<a href="/projects/2015/DSS/paper.pdf"><b>Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images</b></a><br>
				Proceedings of 29th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2016</b>)<br>
				<b style="color: #EE7F2D;">Spotlight Presentation</b>&nbsp;&#183;&nbsp;
				<a href="/projects/2015/DSS/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://dss.cs.princeton.edu">Project Webpage and Source Code</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=zzcipxzZP9E"><img src="/projects/2015/DSS/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>			
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img style="height: 100%;" src="/projects/2016/dilation/dilation_thumb.png"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>F. Yu and V. Koltun<br>
			<a href="https://arxiv.org/abs/1511.07122"><b>Multi-Scale Context Aggregation by Dilated Convolutions</b></a><br>
				International Conference on Learning Representations (<b>ICLR2016</b>)<br>
				<a href="https://arxiv.org/abs/1511.07122">Paper</a>&nbsp;&#183;&nbsp;
				<!-- <a href="https://arxiv.org/abs/1511.07122">Project Webpage</a>&nbsp;&#183;&nbsp; -->
				<a href="https://github.com/fyu/dilation">Code</a>
			</p>
			</td><td style="width: 10px;">
			
			</td>
			</tr></table>			
		</td>
	</tr>		

	<tr style="border-width: 1px">
		<td><img src="/projects/2016/DeepContext/thumbnail.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>Y. Zhang, M. Bai, P. Kohli, S. Izadi, and J. Xiao<br>
			<a href="/projects/2016/DeepContext/paper.pdf"><b>DeepContext: Context-Encoding Neural Pathways for 3D Holistic Scene Understanding</b></a><br>
				arXiv:1603.04922 [cs.2016] (16 Mar 2016)<br>
				<a href="/projects/2016/DeepContext/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://deepcontext.cs.princeton.edu">Project Webpage</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=4kSdErN4W6Q"><img src="/projects/2016/DeepContext/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>			
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/DeepDriving/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>C. Chen, A. Seff, A. Kornhauser and J. Xiao.<br>
			<a href="/projects/2015/DeepDriving/paper.pdf"><b>DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving</b></a><br>
				Proceedings of 15th IEEE International Conference on Computer Vision (<b>ICCV2015</b>)<br>
				<a href="/projects/2015/DeepDriving/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://deepdriving.cs.princeton.edu">Project Webpage, Source Code, and Dataset</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=5hFvoXV9gII"><img src="/projects/2015/DeepDriving/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>	
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/ShapeNet/thumbnail.jpg"></td>
		<td>
			<p>A. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and F. Yu.<br>
			<a href="/projects/2015/ShapeNet/paper.pdf"><b>ShapeNet: An Information-Rich 3D Model Repository</b></a><br>
				arXiv:1512.03012 [cs.CV] 9 Dec 2015<br>
				<a href="/projects/2015/ShapeNet/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://shapenet.org">ShapeNet dataset</a>
			</p>
		</td>
	</tr>
		
	<tr style="border-width: 1px">
		<td><img src="/projects/2015/RobotInARoom/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>S. Song, L. Zhang, and J. Xiao.<br>
			<a href="/projects/2015/RobotInARoom/paper.pdf"><b>Robot In a Room: Toward Perfect Object Recognition in Closed Environments</b></a><br>
				arXiv:1507.02703 [cs.CV] 9 Jul 2015<br>
				<a href="/projects/2015/RobotInARoom/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://3dvision.princeton.edu/projects/2015/RobotInARoom/">Project Webpage and Source Code</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=Et8GEO8qMn0"><img src="/projects/2015/RobotInARoom/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>	
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2014/3DShapeNets/thumbnail.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang and J. Xiao<br>
			<a href="/projects/2014/3DShapeNets/paper.pdf"><b>3D ShapeNets: A Deep Representation for Volumetric Shapes</b></a><br>
				Proceedings of 28th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2015</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="/projects/2014/3DShapeNets/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://3dshapenets.cs.princeton.edu">Source Code and Project Webpage</a>&nbsp;&#183;&nbsp;
				<a href="http://modelnet.cs.princeton.edu">Princeton ModelNet Dataset</a>
			</p>
			</td><td style="width: 10px;">
			<a href="http://techtalks.tv/talks/3d-shapenets-a-deep-representation-for-volumetric-shapes/61589/"><img src="/projects/2014/3DShapeNets/talk.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>			
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/SUNrgbd/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>S. Song, S. Lichtenberg, and J. Xiao<br>
			<a href="/projects/2015/SUNrgbd/paper.pdf"><b>SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite</b></a><br>
				Proceedings of 28th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2015</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="/projects/2015/SUNrgbd/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://rgbd.cs.princeton.edu">Dataset and Project Webpage</a>
			</p>
			</td><td style="width: 10px;">
			<a href="http://techtalks.tv/talks/sun-rgb-d-a-rgb-d-scene-understanding-benchmark-suite/61578/"><img src="/projects/2015/SUNrgbd/talk.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/LSUN/thumbnail.jpg"></td>
		<td>
			<p>F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser and J. Xiao.<br>
			<a href="/projects/2015/LSUN/paper.pdf"><b>LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop</b></a><br>
				arXiv:1506.03365 [cs.CV] 10 Jun 2015<br>
				<a href="http://arxiv.org/abs/1506.03365">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://lsun.yf.io">LSUN dataset</a>
			</p>
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2015/GSValign/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>F. Yu, J. Xiao, and T. Funkhouser<br>
			<a href="/projects/2015/GSValign/paper.pdf"><b>Semantic Alignment of City-Scale LiDAR Data</b></a><br>
				Proceedings of 28th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2015</b>)<br>
				<a href="/projects/2015/GSValign/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="/projects/2015/GSValign/supp.pdf">Supplementary Materials</a>&nbsp;&#183;&nbsp;
				<a href="http://gsv.yf.io">Project Webpage</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=M31vY2u_N5g"><img src="/projects/2015/GSValign/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2014/iSUN/thumbnail.jpg"></td>
		<td>
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>P. Xu, K. A. Ehinger, Y. Zhang, A. Finkelstein, S. R. Kulkarni, and J. Xiao.<br>
			<a href="/projects/2014/iSUN/paper.pdf"><b>TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking</b></a><br>
				arXiv:1504.06755 [cs.CV] 25 Apr 2015<br>
				<a href="/projects/2014/iSUN/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://3dvision.princeton.edu/projects/2014/iSUN/">Project Webpage, Source Code, and iSUN dataset</a>
			</p>
			</td><td style="width: 10px;">
			<a href="https://www.youtube.com/watch?v=jMY-ALt0xh0"><img src="/projects/2014/iSUN/video.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>				
		</td>
	</tr>	

	<tr style="border-width: 1px">
		<td><img src="/projects/2014/SlidingShapes/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>S. Song and J. Xiao<br>
			<a href="/projects/2014/SlidingShapes/paper.pdf"><b>Sliding Shapes for 3D Object Detection in Depth Images</b></a><br>
				Proceedings of the 13th European Conference on Computer Vision (<b>ECCV2014</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="/projects/2014/SlidingShapes/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://slidingshapes.cs.princeton.edu">Source Code and Data and Project Webpage</a>
			</p>
	      	</td><td style="width: 10px;">
			<a href="http://videolectures.net/eccv2014_song_depth_images/"><img src="/projects/2014/SlidingShapes/talk.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>
		</td>
	</tr>


	<tr style="border-width: 1px">
		<td><img src="/projects/2014/PanoContext/thumbnail.jpg"></td>
		<td>

			<table style="width: 100%;"><tr><td style="width: 100%; text-align: left;">
			<p>Y. Zhang, S. Song, P. Tan, and J. Xiao<br>
			<a href="/projects/2014/PanoContext/paper.pdf"><b>PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding</b></a><br>
				Proceedings of the 13th European Conference on Computer Vision (<b>ECCV2014</b>)<br>
				<b style="color: #EE7F2D;">Oral Presentation</b>&nbsp;&#183;&nbsp;
				<a href="/projects/2014/PanoContext/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://panocontext.cs.princeton.edu">Source Code and Data and Project Webpage</a>
			</p>
	      	</td><td style="width: 10px;">
			<a href="http://videolectures.net/eccv2014_zhang_panoramic_scene/"><img src="/projects/2014/PanoContext/talk.jpg" style="width: 130px; height: 85px;"/></a>
			</td>
			</tr></table>
		</td>
	</tr>	

  <tr style="border-width: 1px">
    <td><img src="/projects/2013/tracking/thumbnail.jpg"></td>
    <td bgcolor="#e4e4e4">
      <p>S. Song and J. Xiao<br>
	<a href="/projects/2013/tracking/paper.pdf"><b>Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines</b></a><br>
	Proceedings of 14th IEEE International Conference on Computer Vision (<b>ICCV2013</b>)<br>
	<a href="/projects/2013/tracking/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
	<a href="http://tracking.cs.princeton.edu">Project Webpage, Data, Source Code and Evaluation Server</a> &nbsp;&#183;&nbsp;
	<a href="/projects/2013/tracking/poster.pdf">Poster</a> &nbsp;&#183;&nbsp; <a href="/projects/2013/tracking/spotlight.ppt">Spotlight</a> &nbsp;&#183;&nbsp; <a href="/projects/2013/tracking/slides.pptx">Talk Slides</a> &nbsp;&#183;&nbsp; <a href="/projects/2013/tracking/video.mp4">Video</a>
	</p>
      </td>
    </tr>

  <tr style="border-width: 1px">
    <td><img src="/projects/2013/SUN3D/thumbnail.jpg"></td>
    <td>
      <p>J. Xiao, A. Owens and A. Torralba<br>
	<a href="/projects/2013/SUN3D/paper.pdf"><b>SUN3D: A Database of Big Spaces Reconstructed using SfM and Object Labels</b></a><br>
	Proceedings of 14th IEEE International Conference on Computer Vision (<b>ICCV2013</b>)<br>
	<a href="/projects/2013/SUN3D/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
	<a href="http://sun3d.cs.princeton.edu">Project Webpage, Data and Source Code</a> &nbsp;&#183;&nbsp;
	<a href="/projects/2013/SUN3D/poster.pdf">Poster</a> &nbsp;&#183;&nbsp; <a href="/projects/2013/SUN3D/spotlight.ppt">Spotlight</a> &nbsp;&#183;&nbsp; <a href="/projects/2013/SUN3D/slides/">Talk Slides</a>
	 &nbsp;&#183;&nbsp; Video (<a href="http://3dvision.princeton.edu/projects/2013/SUN3D/video_highres.mp4">HighRes</a>, <a href="http://youtu.be/hxyRj-8CO5c">YouTube</a>)
	</p>
      </td>
    </tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2014/places/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<p>B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva<br>
			<a href="/projects/2014/places/paper.pdf"><b>Learning Deep Features for Scene Recognition using Places Database</b></a><br>
				Advances in Neural Information Processing Systems 27 (<b>NIPS2014</b>)<br>
				<a href="/projects/2014/places/paper.pdf">Paper</a>&nbsp;&#183;&nbsp;
				<a href="http://places.csail.mit.edu">Project Webpage, Data, and Demo</a>
			</p>
		</td>
	</tr>

	<tr style="border-width: 1px">
		<td><img src="/projects/2010/SUN/thumbnail.jpg"></td>
		<td>
			<p>J. Xiao, K. A. Ehinger, J. Hays, A. Torralba, and A. Oliva<br>
			<a href="/projects/2010/SUN/paperIJCV.pdf" ><b><i>SUN Database</i>: Exploring a Large Collection of Scene Categories</b></a><br>
			International Journal of Computer Vision (<b>IJCV</b>)<br>
				<a href="/projects/2010/SUN/paperIJCV.pdf" >Paper</a>
				&nbsp;&#183;&nbsp;
				<a href="http://sun.cs.princeton.edu">Database Webpage</a>
				&nbsp;&#183;&nbsp;
				<a href="/projects/2010/SUN/">Scene Classification Benchmark Webpage</a>
			</p>
		</td>
	</tr>

	<tr>
		<td><img src="/projects/2012/SUN360/thumbnail.jpg"></td>
		<td bgcolor="#e4e4e4">
			<p>J. Xiao, K. A. Ehinger, A. Oliva and A. Torralba<br>
			<a href="/projects/2012/SUN360/paper.pdf" ><b>Recognizing Scene Viewpoint using Panoramic Place Representation</b></a><br>
			Proceedings of 25th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2012</b>)<br>
				<a href="/projects/2012/SUN360/paper.pdf" >Paper</a>&nbsp;&#183;&nbsp;
				<a href="/projects/2012/SUN360/">Project Webpage (Dataset and Source Code)</a>
			</p>
		</td>
	</tr>
</table>

<script type="text/javascript" src="/web/footer.js"></script>
</body></html>
