<!DOCTYPE html>
<!-- saved from url=(0045)http://3dvision.princeton.edu/people/shurans/ ; partially based on Linnan Wang's blog-->
<html class="gr__3dvision_princeton_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Biwei Xie</title>
	<link rel="stylesheet" type="text/css" href="pvg.css">
</head>
<body data-gr-c-s-loaded="true">
<!-- <script type="text/javascript" src="header.js"></script> -->

<br>
<table style="margin-top: 20px;">
<tbody>
<tr >
    <td style="width: 350px;" align="left" >
        <img src="head.jpg" style="width: 240px;">
    </td>

    <td align="left">
        <h1>解壁伟 (Biwei Xie)</h1>
        <p>
        office at 1011F<br>
        Center for Advanced Computer Systems<br>
        Institute of Computing Technology, Chinese Academy of Sciences<br>
        Haidian district, Beijing, China<br>
        </p>

        <p> 
        <a href="https://scholar.google.com/citations?user=KSIiidMAAAAJ&hl=en"> 
        <b>  Google Scholar </b> 
        </a> 
        |&nbsp;
        <a href="https://github.com/puckbee"> 
		<b>  GitHub </b>
		</a>
        </p>
     </td>
</tr>
</tbody>
</table>

<h2>My Mission:</h2>

<p>
Artificial Intelligence is going to be the extension of our brains, in the same way as cars are the extension of our legs. Every day, it finds the best path for us to drive, it recommends excellent restaurants, products, and movies. Overall, it amplifies what we do, augmenting our memory, giving you instant knowledge, allowing us to concentrate on doing things that are properly human.
</p>

<p>
Linnan's mission is democratizing AI, making it accessible to everybody. Any people with any knowledge, any companies of any sizes, any institutions at any places will fully benefit from fantastic AI solutions that are comparable to Google, Facebook, DeepMind with a few simple clicks.
</p>
<p>
Specifically, I'm keen on automating the design of neural architectures for a wide spectrum of applications using modern GPU accelerated Supercomputers. Please feel free to shoot an email to wangnan318@gmail.com if this also piques your interests.
</p>

<p>
I'm a Ph.D. student at the CS department of Brown University, advised by Prof.<a href="http://cs.brown.edu/~rfonseca/">Rodrigo Fonseca</a>. 
Before Brown, I was a <a href="https://www.omscs.gatech.edu"> OMSCS </a> student at Gatech while being a full time software developer at <a href="https://www.dowjones.com"> Dow Jones 
</a>. I acquired my bachelor degree from <a href="http://en.uestc.edu.cn/"> 
University of Electronic Science and Technology of China (UESTC) </a> at the beautiful Qing Shui He campus in 2011. In addition to my advisor, I also work closely with 
<a href="https://scholar.google.com/citations?user=prjpMeoAAAAJ&hl=en">Yiyang Zhao</a>, 
<a href="https://scholar.google.co.jp/citations?user=H0MaUNIAAAAJ&hl=en">Yuu Jinnai</a>,
<a href="https://scholar.google.com/citations?user=dXzhoLgAAAAJ&hl=en">Yi Yang</a>, 
<a href="https://scholar.google.com/citations?user=PCCajlEAAAAJ&hl=en">Wei Wu</a>, 
<a href="https://scholar.google.com/citations?user=37MF6fUAAAAJ&hl=en">George Bosilca</a>, 
<a href="https://scholar.google.com/citations?user=X4SbSTAAAAAJ&hl=en">Jack Dongarra</a>, and 
<a href="https://scholar.google.com/citations?user=Ezrt3pkAAAAJ&hl=en">Maurice Herlihy. </a>
</p>


<h2>in Submission:</h2>

<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">
		
	<tr style="border-width: 1px">
		<td><img src="arch_paper.png" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Yiyang Zhao, Yuu Jinnai<br>
			<a href="http://arxiv.org/abs/1805.07440"> <b>AlphaX: eXploring Neural Architectures with Deep Neural Networks and Monte Carlo Tree Search</b> </a> <br>
 			<a href="http://arxiv.org/abs/1805.07440">Paper</a>&nbsp;
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	<tr style="border-width: 1px">
		<td><img src="grad_comp.jpg" height = "270" width = "400" ></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			<b>Wang, Linnan</b>, Wei Wu, Yiyang Zhao, Hang Liu, George Bosilca, Jack Dongarra, Maurice Herlihy, Rodrigo Fonseca <br>
			<b>SuperNeurons: Gradient Compression in the Distributed Training of Deep Neural Networks</b> <br>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	</table>

<h2>Publications:</h2>
<b>2018</b>
<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">
	<tbody>
		
	<tr style="border-width: 1px">
		<td><img src="adapt.png" height = "270" width = "400"></td>
		<td>
		<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			Luo, Xi , Wei Wu, George Bosilca, Thananon Patinyasakdikul, <b>Linnan Wang</b>, Jack Dongarra<br>
			<a href="https://dl.acm.org/citation.cfm?id=3208054"><b>ADAPT: An Event-based Adaptive Collective Communication Framework</b> </a> <br>
			In Proceedings of 27th ACM International Symposium on High-Performance Parallel and Distributed Computing (<b>HPDC2018</b>)<br>
 			<a href="https://dl.acm.org/citation.cfm?id=3208054">Paper</a>&nbsp;
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody>
		</table>
		</td>
	</tr>
	
	<tr style="border-width: 1px">
		<td><img src="warp_consolidation.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>
			Li, Ang, Weifeng Liu, <b>Linnan Wang</b>, Kevin Barker, Shuaiwen Leon Song<br>
			<a href="http://www.idi.ntnu.no/~weifengl/papers/warpconsolidation_li_ics18.pdf"> <b>Warp-Consolidation: A Novel Execution Model for Modern GPUs</b> </a> <br>
			In Proceedings of the 2018 International Conference on Supercomputing (<b>ICS2018</b>)<br>
 			<a href="http://www.idi.ntnu.no/~weifengl/papers/warpconsolidation_li_ics18.pdf">Paper</a>&nbsp;
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr>
	        </tbody></table>			
		</td>
	</tr>
	
    <tr style="border-width: 1px">
 		<td><img src="automl.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>Carsten Binnig, et al. <br>
 			<a href="http://www.sysml.cc/doc/118.pdf"><b>Towards Interactive Curation & Automatic Tuning of ML Pipelines</b></a><br>
			SysML Conference (<b>SysML2018</b>)<br>
 			<a href="http://www.sysml.cc/doc/118.pdf">Paper</a>&nbsp;
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
		
    <tr style="border-width: 1px">
 		<td><img src="trnn.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p>Ye, Jinmian, <b>Linnan Wang</b>, Guangxi Li, Di Chen, Shandian Zhe, Xinqi Chu, Zenglin Xu <br>
 			<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.pdf"><b>Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition</b></a><br>
			In Proceedings of 31th IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR2018</b>)<br>
 			<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.pdf">Paper</a>&nbsp;·&nbsp;
			<a href="cvpr_poster.pdf">Poster</a>&nbsp;
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>
	
    <tr style="border-width: 1px">
 		<td><img src="superneurons.png" height = "270" width = "400"></td>
 		<td>
 			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
 			<p><b>Wang, Linnan</b>, Jinmian Ye, Yiyang Zhao, Wei Wu, Ang Li, Shuaiwen Leon Song, Zenglin Xu, Tim Kraska<br>
 			<a href="https://dl.acm.org/citation.cfm?id=3178491"><b>SuperNeurons:Dynamic GPU Memory Management for Training Deep Nonlinear Neural Networks</b></a><br>
 				In Proceedings of the 23nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (<b>PPoPP2018</b>)<br>
 				<a href="https://dl.acm.org/citation.cfm?id=3178491">Paper</a>&nbsp;·&nbsp;
 				<a href="https://www.youtube.com/watch?v=y2h5AOwMnYs">Talk</a>&nbsp;·&nbsp;
				<a href="superneurons_talk.pptx"> Presentation </a>&nbsp;·&nbsp;
				<a href="https://github.com/linnanwang/superneurons-release"> Code </a>
 			</p>
 			</td><td style="width: 10px;">
 			</td>
 			</tr></tbody></table>			
 		</td>
    </tr>

    </tbody>
   
   </tbody>
</table>

<b>2017</b>
<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">

	<tbody>
   	<tr style="border-width: 1px">
		<td><img src="isgd.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p> <b>Wang, Linnan</b>, Yi Yang, Renqiang Min, and Srimat Chakradhar<br>
			<a href="http://www.sciencedirect.com/science/article/pii/S0893608017301399">
			<b>Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent</b></a><br>
			    Neural Networks (2017)<br>
				<a href="http://www.sciencedirect.com/science/article/pii/S0893608017301399">Paper</a>&nbsp;·&nbsp;
				<a href="https://patents.google.com/patent/US20170228645A1/en?q=Accelerating&q=deep&q=neural+network&q=training&q=inconsistent&q=stochastic+gradient+descent">Patent</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr></tbody></table>			
		</td>
   </tr>
   
   <tr style="border-width: 1px">
		<td><img src="efficient_comm.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p> Zhao, Yiyang, <b>Linnan Wang</b>, Wei Wu, George Bosilca, Richard Vuduc, Jinmian Ye, Wenqi Tang, and Zenglin Xu. <br>
			<a href="http://www.icl.utk.edu/files/publications/2017/icl-utk-966-2017.pdf">
			<b>Efficient Communications in Training Large Scale Neural Networks</b></a><br>
			In Proceedings of the 25th ACM international conference on Multimedia (<b>MM2017</b>)<br>	
			<a href="http://www.icl.utk.edu/files/publications/2017/icl-utk-966-2017.pdf">Paper</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr></tbody></table>			
		</td>
   </tr>
   
   <tr style="border-width: 1px">
		<td><img src="p2t2f.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p>Li, Guangxi, Zenglin Xu, <b>Linnan Wang</b>, Jinmian Ye, Irwin King, and Michael Lyu<br>
			<a href="https://arxiv.org/pdf/1611.03578.pdf"><b>Simple and Efficient Parallelization for Probabilistic Temporal Tensor Factorization</b></a><br>
				In 2017 International Joint Conference on Neural Networks (<b>IJCNN2017</b>)<br>
				<a href="https://arxiv.org/pdf/1611.03578.pdf">Paper</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr></tbody></table>			
		</td>
   </tr>
</tbody>
</table>

<b>2016</b>
<table id="pubList" border="0" cellpadding="0" width="100%" style="border-spacing: 0 6px; line-height:14pt;">
	<tbody>
   <tr style="border-width: 1px">
		<td><img src="BLASX.png" height = "270" width = "400"></td>
		<td>
			<table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
			<p><b>Wang, Linnan</b>, Wei Wu, Zenglin Xu, Jianxiong Xiao, and Yi Yang<br>
			<a href="http://dl.acm.org/citation.cfm?id=2926256"><b>BLASX: A High Performance Level-3 BLAS Library for Heterogeneous MultiGPU Computing</b></a><br>
				In Proceedings of the 2016 International Conference on Supercomputing (<b>ICS2016</b>)<br>
				<a href="http://dl.acm.org/citation.cfm?id=2926256">Paper</a>&nbsp;·&nbsp;
				<a href="http://sc15.supercomputing.org/sites/all/themes/SC15images/tech_poster/poster_files/post108s2-file2.pdf">SC Poster</a>&nbsp;·&nbsp;
				<a href="https://github.com/linnanwang/BLASX">Code</a>&nbsp;·&nbsp;
				<a href="blasx_talk.pptx">Presentation</a>
			</p>
			</td><td style="width: 10px;">
			</td>
			</tr></tbody></table>			
		</td>
   </tr>
   
   </tbody>
</table>

<!-- <h2>Other Projects:</h2>
<table id="pubList" border=0 cellpadding=0 width=100% style="border-spacing: 0 6px; line-height:14pt;">
<tr style="border-width: 1px">
	<td><img src="/marvin/marvin.svg" ></td>
	<td>
		<b>Marvin: A Minimalist GPU-only N-dimensional ConvNet Framework</b><br>
			<a href="http://marvin.is">Project Webpage</a>
		</p>
	</td>
</tr>
<tr style="border-width: 1px">
	<td><img src="/people/shurans/imgs/robot4.jpg" ></td>
	<td>
		<b>Amazon Picking Challenge Competition 2016 (MIT + Princeton team)</b><br>
		<a href="http://www.cs.princeton.edu/~andyz//apc2016">Project Webpage</a>
		
		</p>
	</td>
</tr>

</table> -->

<h2>Patent:</h2>
<ul>
<li><a href="https://patents.google.com/patent/US20170228645A1/en?q=Accelerating&q=deep&q=neural+network&q=training&q=inconsistent&q=stochastic+gradient+descent"> US20170228645A1</a>,  Inconsistent Stochastic Gradient Descent, NEC Labs
</li>
</ul>


<h2>Awards:</h2>
<ul>
<li> Brown Fellowship (2017-2018) </li>
</ul>

 
<h2>Academic Services:</h2>
<ul>
<li>Reviewer of Journal of Machine Learning Research (JMLR), 2017</li>
<li>Reviewer of Neural Information Processing System (NIPS), 2016</li>
</ul>



<h2>Professional Experiences:</h2>
<ul>
<li>Research Intern, Microsoft Research AI, Redmond, 2018.May ~ 2018.August </li>
<li>Research Intern, NEC Labs, Princeton, 2016.Aug ~ 2017.Jan </li>
<li>Software Developer, Dow Jones, Princeton, 2014.Aug ~ 2016.Aug </li>
</ul>

</body></html>
